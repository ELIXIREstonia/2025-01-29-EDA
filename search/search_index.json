{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#elixir-ee-exploratory-data-analysis-eda-with-r","title":"ELIXIR EE Exploratory Data Analysis (EDA) with R","text":""},{"location":"#lesson-overview","title":"Lesson overview","text":"<p> Description Workshop: Introduction to Exploratory Data Analysis (EDA) with R</p> <p>Are you ready to unlock the potential of your data? This one-day workshop will introduce you to Exploratory Data Analysis (EDA)\u2014an essential first step in any data analysis workflow. Designed for graduate-level learners without a computational background, this course will equip you with the foundational skills to summarize, visualize, and interpret data effectively.</p> <p></p> <p> Prerequisites To be able to follow this course, learners should: \u20031. Bring your own laptop and install R and RStudio (see Setup for details). \u20032. install \u2018tidyverse\u2019 package (in R: <code>install.packages(\"tidyverse\")</code>)  </p> <p></p> <p> Learning Outcomes: By the end of the course, learners will be able to: \u2003- Define key concepts and principles of exploratory data analysis (EDA) and explain its importance in the data analysis workflow. \u2003- Identify and describe common types of data (numerical, categorical) and the appropriate statistical summaries and visualizations for each. \u2003- Generate basic descriptive statistics (e.g., mean, median, standard deviation) and visualizations (e.g., histograms, scatterplots, boxplots) using R. \u2003- Evaluate datasets for common issues, such as missing values, outliers, and inconsistencies, and apply basic techniques to address these issues (e.g., imputation, normalization). \u2003- Interpret key results from visualizations and statistical summaries to recognize patterns, trends, and anomalies in the data. \u2003- Propose appropriate next steps for deeper analysis or preprocessing based on findings during the exploratory data analysis process.  </p> <p></p> <p> Level: Beginner</p> <p> License: Creative Commons Attribution 4.0 International License</p>"},{"location":"#contributors","title":"Contributors","text":"<p> Priit Adler </p> <p></p> <p> ChatGPT </p>"},{"location":"#setup","title":"Setup","text":""},{"location":"#data-setup","title":"Data setup","text":"<p>\u20031. Download the data from here</p>"},{"location":"#software-used-in-this-lesson","title":"Software used in this lesson:","text":"<p>\u20031. R - in addition install \u2018tidyverse\u2019 package (<code>install.packages(\"tidyverse\")</code>)  \u20032. RStudio \u20033. Git - optional, suggested \u20034. Visual Studio Code - optional </p>"},{"location":"course_schedule/","title":"Course schedule","text":"start end topic 10:00 10:30 coffee! 12:00 13:00 lunch! <p>Generate markdown tables at tablesgenerator.com</p>"},{"location":"follow_up_training/","title":"Follow up training","text":"<p>lorem ipsum</p>"},{"location":"keywords/","title":"Keywords","text":"<p>Here\u2019s a list of used keywords:</p> <ol> <li> <p>Nancy J Hoebelheinrich, Katarzyna Biernacka, Michelle Brazas, Leyla Jael Castro, Nicola Fiore, Margareta Hellstrom, Emma Lazzeri, Ellen Leenarts, Paula Maria Martinez Lavanchy, Elizabeth Newbold, Amy Nurnberger, Esther Plomp, Lucia Vaira, Celia W G van Gelder, and Angus Whyte. Recommendations for a minimal metadata set to aid harmonised discovery of learning resources. June 2022. URL: https://doi.org/10.15497/RDA00073, doi:10.15497/RDA00073.\u00a0\u21a9</p> </li> <li> <p>Leyla Garcia, B\u00e9r\u00e9nice Batut, Melissa L. Burke, Mateusz Kuzak, Fotis Psomopoulos, Ricardo Arcila, Teresa K. Attwood, Niall Beard, Denise Carvalho-Silva, Alexandros C. Dimopoulos, Victoria Dominguez Del Angel, Michel Dumontier, Kim T. Gurwitz, Roland Krause, Peter McQuilton, Loredana Le Pera, Sarah L. Morgan, P\u00e4ivi Rauste, Allegra Via, Pascal Kahlem, Gabriella Rustici, Celia W.G. Van Gelder, and Patricia M. Palagi. Ten simple rules for making training materials FAIR. PLoS Computational Biology, 16(5):1\u20139, 2020. doi:10.1371/journal.pcbi.1007854.\u00a0\u21a9</p> </li> <li> <p>When we share, everyone wins. Accessed: 2022-08-11. URL: https://creativecommons.org/.\u00a0\u21a9</p> </li> <li> <p>Open source licenses: types and comparison. Accessed: 2023-02-10. URL: https://snyk.io/learn/open-source-licenses/.\u00a0\u21a9</p> </li> <li> <p>Jon Ison, Mat\u00fa\u0161 Kala\u0161, Inge Jonassen, Dan Bolser, Mahmut Uludag, Hamish McWilliam, James Malone, Rodrigo Lopez, Steve Pettifer, and Peter Rice. EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats. Bioinformatics, 29(10):1325\u20131332, 03 2013. URL: https://doi.org/10.1093/bioinformatics/btt113, arXiv:https://academic.oup.com/bioinformatics/article-pdf/29/10/1325/710075/btt113.pdf, doi:10.1093/bioinformatics/btt113.\u00a0\u21a9</p> </li> <li> <p>Scott Chacon and Ben Straub. Pro Git. Apress, 2014. URL: https://git-scm.com/book/en/v2.\u00a0\u21a9</p> </li> <li> <p>Visual Studio Code Documentation Team. Source control in visual studio code. Accessed: 2024-11-05. URL: https://code.visualstudio.com/docs/sourcecontrol/overview.\u00a0\u21a9</p> </li> <li> <p>GitHub Documentation Team. Caching Your GitHub Credentials in Git. Accessed: 2024-11-05. URL: https://docs.github.com/en/get-started/getting-started-with-git/caching-your-github-credentials-in-git.mkdocs\u00a0\u21a9</p> </li> </ol>"},{"location":"chapters/01_introduction/","title":"Introduction","text":""},{"location":"chapters/01_introduction/#introduction-to-exploratory-data-analysis-eda-with-r","title":"Introduction to Exploratory Data Analysis (EDA) with R","text":"<p>Welcome to the \u201cIntroduction to Exploratory Data Analysis (EDA) with R\u201d workshop! This one-day course is designed for graduate-level learners without a computational background. Our goal is to equip you with the foundational skills needed to summarize, visualize, and interpret data effectively.</p>"},{"location":"chapters/01_introduction/#what-is-eda","title":"What is EDA?","text":"<p>Exploratory Data Analysis (EDA) is an essential first step in any data analysis workflow. It involves summarizing the main characteristics of a dataset, often using visual methods. EDA helps you understand the data, uncover patterns, spot anomalies, and test hypotheses.</p>"},{"location":"chapters/01_introduction/#types-of-data","title":"Types of Data","text":"<p>Understanding the types of data you are working with is crucial for effective analysis. Data can generally be categorized into two main types:</p>"},{"location":"chapters/01_introduction/#numerical-data","title":"Numerical Data","text":"<p>Numerical data represents quantities and can be further divided into: - Continuous Data: Data that can take any value within a range (e.g., height, weight). - Discrete Data: Data that can only take specific values (e.g., number of students in a class).</p>"},{"location":"chapters/01_introduction/#categorical-data","title":"Categorical Data","text":"<p>Categorical data represents characteristics and can be divided into: - Nominal Data: Data with categories that do not have a natural order (e.g., gender, color). - Ordinal Data: Data with categories that have a natural order (e.g., rankings, satisfaction levels).</p>"},{"location":"chapters/01_introduction/#primary-visualizations-and-statistical-summaries","title":"Primary Visualizations and Statistical Summaries","text":"<p>Different types of data require different visualization techniques. </p> <p>When deciding how to visualize data, refer to: - Data-to-Viz: Provides guidance on choosing the right chart for specific data types and objectives. - R Graph Gallery: Offers a large collection of R graphical examples, complete with code snippets.</p> <p>The Data-to-Viz and R Graph Gallery websites provide extensive collections of visualization examples. Each example is accompanied by an explanation of the relevant theory and example code in R. These resources can help you choose the most appropriate visualization for your data.</p>"},{"location":"chapters/01_introduction/#introduction-to-tidyverse","title":"Introduction to <code>tidyverse</code>","text":"<p>The <code>tidyverse</code> is a collection of R packages designed for data science. It includes packages like <code>ggplot2</code> for data visualization, <code>dplyr</code> for data manipulation, and <code>tidyr</code> for data tidying. Throughout this workshop, we will use functions from the <code>tidyverse</code> to perform EDA.</p> <p>To install and load the <code>tidyverse</code>, use the following commands: </p><pre><code>install.packages(\"tidyverse\")\nlibrary(tidyverse)\n</code></pre> Define a Sample Dataset  Here is an example of how to define a sample dataset with two categorical columns and three numeric columns (one from a uniform distribution, one from a normal distribution, and one from a binomial distribution):  <pre><code># Define a sample dataset\nset.seed(123)\ndata &lt;- data.frame(\n  drug = sample(c(\"DrugA\", \"DrugB\", \"DrugC\"), 100, replace = TRUE),\n  gender = sample(c(\"Male\", \"Female\"), 100, replace = TRUE),\n  height = runif(100, min = 150, max = 200),  # Uniform distribution\n  age = rnorm(100, mean = 50, sd = 10),      # Normal distribution\n  response = rbinom(100, size = 1, prob = 0.5) # Binomial distribution\n)\n\n# Display the first few rows of the dataset\nhead(data)\n</code></pre>"},{"location":"chapters/01_introduction/#numerical-data_1","title":"Numerical Data","text":"<p>For numerical data, the following techniques are commonly used:</p> <ul> <li> <p>Descriptive Statistics: Calculate measures such as mean, median, standard deviation, and range to summarize the data. </p><pre><code># Calculate summary statistics\nsummary(data$height)\n&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n&gt;   150.3   161.2   173.7   174.0   187.0   199.1 \ndata %&gt;% summarise(mean = mean(height), median = median(height), sd = sd(height))\n&gt;       mean   median       sd\n&gt; 1 174.0325 173.7355 14.75736\n</code></pre> </li> <li> <p>Histograms: Visualize the distribution of the data by showing the frequency of data points within specified ranges. </p><pre><code># Create a histogram\nggplot(data, aes(x = height)) + geom_histogram(binwidth = 2)\n</code></pre> </li> <li> <p>Boxplots: Display the distribution of the data based on a five-number summary (minimum, first quartile, median, third quartile, and maximum) and identify outliers. </p><pre><code># Create a boxplot\nggplot(data, aes(y = height)) + geom_boxplot()\n</code></pre> </li> <li> <p>Scatterplots: Plot pairs of numerical data to identify relationships or correlations between variables. </p><pre><code># Create a scatterplot\nggplot(data, aes(x = height, y = age)) + geom_point()\n</code></pre> </li> <li> <p>Line Graphs: Show trends over time or ordered categories. </p><pre><code># Create a line graph\nggplot(data, aes(x = 1:100, y = height)) + geom_line()\n</code></pre> </li> </ul>"},{"location":"chapters/01_introduction/#categorical-data_1","title":"Categorical Data","text":"<p>For categorical data, the following techniques are commonly used:</p> <ul> <li> <p>Frequency Tables: Summarize the data by counting the occurrences of each category. </p><pre><code># Create a frequency table\ntable(data$drug)\n&gt; DrugA DrugB DrugC \n&gt;    33    32    35 \ndata %&gt;% count(drug)\n&gt;    drug  n\n&gt; 1 DrugA 33\n&gt; 2 DrugB 32\n&gt; 3 DrugC 35\n</code></pre> </li> <li> <p>Bar Charts: Visualize the frequency or proportion of categories using bars. </p><pre><code># Create a bar chart\nggplot(data, aes(x = drug)) + geom_bar()\n</code></pre> </li> <li> <p>Mosaic Plots: Show the relationship between two or more categorical variables by dividing a rectangle into proportional areas. </p><pre><code># Create a mosaic plot\ninstall.packages(\"ggmosaic\")\nlibrary(ggmosaic)\nggplot(data) + \n  geom_mosaic(aes(weight = response, x = product(drug), fill = gender))\n</code></pre> </li> </ul>"},{"location":"chapters/01_introduction/#concept-test","title":"Concept Test","text":"<p>Let\u2019s test your understanding of the concepts covered so far. Try to answer the following questions:</p> <ol> <li>What is the difference between continuous and discrete numerical data?</li> </ol> Answer Continuous data can take any value within a range (e.g., height, weight), while discrete data can only take specific values (e.g., number of students in a class).  <ol> <li>What are the main differences between nominal and ordinal categorical data?</li> </ol> Answer Nominal data has categories without a natural order (e.g., gender, color), while ordinal data has categories with a natural order (e.g., rankings, satisfaction levels).  <ol> <li>Which R package from the <code>tidyverse</code> is primarily used for data visualization?</li> </ol> Answer The `ggplot2` package is primarily used for data visualization in the `tidyverse`."},{"location":"chapters/01_introduction/#task","title":"Task","text":"<p>Visit the Data-to-Viz website and find the recommended visualizations for a dataset containing a numerical and a categorical data, there are many obsevations per category. Which one you would choose. Can you find the R code to create that visualization (hint: R Graph Gallery)?</p>"},{"location":"chapters/01_introduction/#conclusion","title":"Conclusion","text":"<p>In this chapter, we introduced the basics of Exploratory Data Analysis (EDA) and discussed different types of data and their visualization techniques. We also provided R code examples using the <code>tidyverse</code> package to help you get started with EDA. In the next chapters, we will dive deeper into more advanced techniques and real-world applications of EDA.</p>"},{"location":"chapters/02_EDA_process/","title":"Workflow","text":""},{"location":"chapters/02_EDA_process/#the-exploratory-data-analysis-eda-process","title":"The Exploratory Data Analysis (EDA) Process","text":"<p>Exploratory Data Analysis (EDA) is a crucial step in the data analysis workflow. It involves examining the data to understand its main characteristics, uncover patterns, spot anomalies, and test hypotheses. This guide will help you understand where to start, the steps involved, and what to consider at each step.</p>"},{"location":"chapters/02_EDA_process/#document-the-process","title":"Document the Process","text":"<p>Document your findings and the steps you took during the EDA process: - Summary Report: Create a summary report of your findings, including visualizations and key statistics. - Code Documentation: Document the code used for data cleaning, exploration, and visualization.</p> <p>Excellent medium for the code and documentation is R Markdown. It allows you to combine code, text, and visualizations in a single document - See Rstudio R Markdown Guide for more information.</p>"},{"location":"chapters/02_EDA_process/#step-1-understand-the-data-context","title":"Step 1: Understand the Data Context","text":"<p>Before diving into the data, it\u2019s essential to understand the context: - Objective: What is the goal of the analysis? - Data Source: Where does the data come from? - Data Collection Method: How was the data collected? - Variables: What are the variables in the dataset, and what do they represent?</p>"},{"location":"chapters/02_EDA_process/#step-2-data-cleaning","title":"Step 2: Data Cleaning","text":"<p>Data cleaning is the process of preparing the data for analysis. This step includes: - Handling Missing Values: Identify and decide how to handle missing data (e.g., imputation, removal).   </p><pre><code># Identify missing values\nsum(is.na(data))\n\n# Remove rows with missing values\ndata &lt;- na.omit(data)\n</code></pre> - Removing Duplicates: Check for and remove duplicate records.   <pre><code># Remove duplicate rows\ndata &lt;- data[!duplicated(data), ]\n</code></pre> - Correcting Errors: Identify and correct any errors or inconsistencies in the data.   <pre><code># Example: Correcting a specific error\ndata$variable[data$variable == \"incorrect_value\"] &lt;- \"correct_value\"\n</code></pre> - Data Transformation: Transform data types if necessary (e.g., converting strings to dates).   <pre><code># Convert string to date\ndata$date &lt;- as.Date(data$date, format = \"%Y-%m-%d\")\n</code></pre> <p>Sometimes, especially for data that has been collected manually, it would be more efficient to use a dedicated tool for data cleaning, such as OpenRefine. See our OpenRefine training materials</p>"},{"location":"chapters/02_EDA_process/#step-3-initial-data-exploration","title":"Step 3: Initial Data Exploration","text":"<p>Perform an initial exploration to get a sense of the data: - Summary Statistics: Calculate summary statistics (mean, median, standard deviation, etc.) for numerical variables.   </p><pre><code># Summary statistics\nsummary(data$variable)\n</code></pre> - Frequency Tables: Create frequency tables for categorical variables.   <pre><code># Frequency table\ntable(data$category)\n</code></pre> - Visualizations: Use basic visualizations (histograms, bar charts, boxplots) to understand the distribution of the data.   <pre><code># Histogram\nggplot(data, aes(x = variable)) + geom_histogram(binwidth = 1)\n\n# Bar chart\nggplot(data, aes(x = category)) + geom_bar()\n</code></pre> - Outliers: Detect outliers and decide how to handle them.   <pre><code># Boxplot to detect outliers\nggplot(data, aes(y = variable)) + geom_boxplot()\n</code></pre>"},{"location":"chapters/02_EDA_process/#step-4-data-normalization","title":"Step 4: Data Normalization","text":"<p>Normalization is the process of scaling numerical data to a standard range, typically [0, 1] or [-1, 1]. This step is important when the data has different units or scales, which can affect the results of the analysis.</p>"},{"location":"chapters/02_EDA_process/#when-to-normalize","title":"When to Normalize","text":"<ul> <li>When the data has different units or scales.  </li> <li>Before applying machine learning algorithms that are sensitive to the scale of the data (e.g., k-means clustering, principal component analysis).  </li> <li>Before applying statistical tests that assume normality or require standardized data.</li> </ul>"},{"location":"chapters/02_EDA_process/#common-r-methods-for-normalization","title":"Common R Methods for Normalization","text":"<ul> <li>Min-Max Scaling: Scales the data to a range of [0, 1].   <pre><code># Min-Max Scaling\ndata$variable_min_max &lt;- (data$variable - min(data$variable)) / (max(data$variable) - min(data$variable))\n</code></pre></li> <li>Z-Score Standardization: Scales the data to have a mean of 0 and a standard deviation of 1.   <pre><code># Z-Score Standardization\ndata$variable_Z &lt;- scale(data$variable)\n</code></pre></li> <li>Log Transformation: Transforms skewed data to a more normal distribution.   <pre><code># Log Transformation\ndata$variable_log &lt;- log(data$variable + 1)\n</code></pre></li> <li>VSN Transformation: Normalizes data using variance stabilizing normalization.   <pre><code># VSN Transformation\nlibrary(vsn)\ndata$variable_vsn &lt;- vsn::vsn2(data$variable)\n</code></pre></li> </ul>"},{"location":"chapters/02_EDA_process/#step-5-detailed-data-exploration","title":"Step 5: Detailed Data Exploration","text":"<p>Dive deeper into the data to uncover patterns and relationships: - Correlation Analysis: Examine correlations between numerical variables.   </p><pre><code># Correlation matrix\ncor(data[, sapply(data, is.numeric)])\n\n# Scatterplot for visual correlation\nggplot(data, aes(x = variable1, y = variable2)) + geom_point()\n</code></pre> - Cross-Tabulation: Explore relationships between categorical variables.   <pre><code># Cross-tabulation\ntable(data$category1, data$category2)\n</code></pre> - Advanced Visualizations: Use scatterplots, heatmaps, and other advanced visualizations to explore relationships.   <pre><code># Heatmap\nlibrary(reshape2)\ndata_melt &lt;- melt(cor(data[, sapply(data, is.numeric)]))\nggplot(data_melt, aes(Var1, Var2, fill = value)) + geom_tile()\n</code></pre> - Trends: Identify trends over time or across categories.   <pre><code># Line plot for trends over time\nggplot(data, aes(x = time, y = variable)) + geom_line()\n</code></pre> - Clusters: Identify clusters or groups within the data.   <pre><code># K-means clustering\nset.seed(123)\nclusters &lt;- kmeans(data[, sapply(data, is.numeric)], centers = 3)\ndata$cluster &lt;- as.factor(clusters$cluster)\n\n# Scatterplot with clusters\nggplot(data, aes(x = variable1, y = variable2, color = cluster)) + geom_point()\n</code></pre>"},{"location":"chapters/02_EDA_process/#step-6-formulate-hypotheses","title":"Step 6: Formulate Hypotheses","text":"<p>Based on your exploration, formulate hypotheses about the data: - Hypothesis Generation: Develop hypotheses that can be tested with further analysis. - Preliminary Insights: Summarize preliminary insights and observations.</p>"},{"location":"chapters/02_EDA_process/#next-steps","title":"Next Steps","text":"<p>Conclude the EDA process when you have a good understanding of the data: - Sufficient Exploration: Ensure that you have sufficiently explored the data and addressed any anomalies. - Clear Insights: Make sure you have clear insights and hypotheses to guide further analysis.</p> <p>After completing EDA, the next steps typically involve: - Hypothesis Testing: Use statistical tests to validate your hypotheses. - Model Building: Develop predictive models based on the insights gained from EDA. - Reporting: Create detailed reports and presentations to communicate your findings.</p>"},{"location":"chapters/02_EDA_process/#concept-test","title":"Concept Test","text":"<p>Let\u2019s test your understanding of the EDA process. Try to answer the following questions:</p> <ol> <li>What are the key steps involved in the EDA process?</li> </ol> Answer The key steps are: Understand the Data Context, Data Cleaning, Initial Data Exploration, Data Normalization, Detailed Data Exploration, Formulate Hypotheses.  <ol> <li>Why is it important to understand the data context before starting EDA?</li> </ol> Answer Understanding the data context helps you know the objective of the analysis, the source of the data, how it was collected, and what the variables represent. This knowledge is crucial for making informed decisions during the EDA process.  <ol> <li>What are some common techniques for handling missing values in a dataset?</li> </ol> Answer Common techniques include removing rows with missing values, imputing missing values with the mean, median, or mode, and using more advanced imputation methods like k-nearest neighbors or regression imputation are possible, but I would avoid them if sample size allows for removal.  <ol> <li>When should you consider normalizing your data, and what are common methods for normalization in R?</li> </ol> Answer You should consider normalizing your data when it has different units or scales, or before applying machine learning algorithms that are sensitive to the scale of the data. Common methods for normalization in R include Min-Max Scaling and Z-Score Standardization.  <p>By following these steps, you can effectively perform EDA and gain valuable insights from your data. Remember that EDA is an iterative process, and you may need to revisit some steps as you uncover new information.</p>"},{"location":"chapters/03_practice/","title":"Practice","text":""},{"location":"chapters/03_practice/#practice-exploratory-data-analysis-eda","title":"Practice: Exploratory Data Analysis (EDA)","text":"<p>In this practice session, you will apply the concepts learned in the previous chapters to perform EDA on a sample dataset. You will need to download the prepared Rmarkdown document and open it in RStudio.</p>"},{"location":"chapters/03_practice/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Download the Rmarkdown Document: Click here to download the Rmarkdown (.Rmd) file to your local machine.</p> </li> <li> <p>Download the Dataset: Download the sample dataset from here</p> </li> <li> <p>Open RStudio: Launch RStudio on your computer.</p> </li> <li> <p>Open the Rmarkdown Document: In RStudio, go to <code>File</code> &gt; <code>Open File...</code> and select the downloaded .Rmd file.</p> </li> <li> <p>Install Required Packages: Ensure you have the necessary packages installed. You can run the following code in your R console to install the <code>tidyverse</code> package if you haven\u2019t already:    </p><pre><code>install.packages(\"tidyverse\")\n</code></pre> </li> <li> <p>Run the Code Chunks: Execute the code chunks in the Rmarkdown document by clicking the green play button (<code>Run Current Chunk</code>) at the top right of each code chunk or by pressing <code>Ctrl + Alt + C</code> (Windows) or <code>Cmd + Option + C</code> (Mac).</p> </li> </ol>"},{"location":"chapters/03_practice/#completing-the-tasks","title":"Completing the Tasks","text":"<p>The Rmarkdown document contains a series of tasks that you need to complete. Each task is designed to help you practice different aspects of EDA, including data cleaning, initial exploration, detailed exploration, and visualization.</p>"},{"location":"chapters/03_practice/#conclusion","title":"Conclusion","text":"<p>Once you have completed the tasks, save your Rmarkdown. You can then share your work with others or use it as a reference for future projects.</p> <p>By following these steps and completing the tasks, you will gain hands-on experience with EDA and reinforce the concepts covered in the workshop. Good luck!</p>"},{"location":"chapters/05_grammar_of_graphics/","title":"Grammar of Graphics","text":""},{"location":"chapters/05_grammar_of_graphics/#understanding-ggplot2-graphics-grammar","title":"Understanding <code>ggplot2</code> Graphics Grammar","text":"<p><code>ggplot2</code> is a powerful and flexible R package for creating data visualizations. It is based on the Grammar of Graphics, which provides a coherent system for describing and building graphs. This chapter will serve as a self-study reference on how to manage <code>ggplot2</code> syntax.</p>"},{"location":"chapters/05_grammar_of_graphics/#providing-data","title":"Providing Data","text":"<p>The first step in creating a plot with <code>ggplot2</code> is to provide the data. The data should be in a data frame format.</p> <pre><code># Load the ggplot2 package\nlibrary(ggplot2)\n\n# Example data frame\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = rnorm(100)\n)\n</code></pre>"},{"location":"chapters/05_grammar_of_graphics/#defining-aesthetics","title":"Defining Aesthetics","text":"<p>Aesthetics (aes) are the visual properties of the objects in your plot, such as position, color, shape, and size. You define aesthetics using the <code>aes()</code> function.</p> <pre><code># Define aesthetics\nggplot(data, aes(x = x, y = y))\n</code></pre>"},{"location":"chapters/05_grammar_of_graphics/#choosing-geoms","title":"Choosing Geoms","text":"<p>Geoms (geometric objects) are the actual marks we put on a plot. Examples include points, lines, bars, and histograms. You add geoms to your plot using functions like <code>geom_point()</code>, <code>geom_line()</code>, <code>geom_bar()</code>, etc.</p> <pre><code># Add points to the plot\nggplot(data, aes(x = x, y = y)) + geom_point()\n</code></pre>"},{"location":"chapters/05_grammar_of_graphics/#fine-tuning-scales","title":"Fine-Tuning Scales","text":"<p>Scales control the mapping from data to aesthetics. You can adjust scales to change the appearance of your plot, such as axis labels, limits, and breaks.</p> <pre><code># Adjust scales\nggplot(data, aes(x = x, y = y)) + \n  geom_point() + \n  scale_x_continuous(name = \"X Axis\", limits = c(-3, 3), breaks = seq(-3, 3, 1)) +\n  scale_y_continuous(name = \"Y Axis\", limits = c(-3, 3), breaks = seq(-3, 3, 1))\n</code></pre>"},{"location":"chapters/05_grammar_of_graphics/#customizing-themes","title":"Customizing Themes","text":"<p>Themes control the non-data elements of your plot, such as the background, grid lines, and text. You can customize themes using the <code>theme()</code> function or apply pre-built themes like <code>theme_minimal()</code>, <code>theme_classic()</code>, etc.</p> <pre><code># Customize theme\nggplot(data, aes(x = x, y = y)) + \n  geom_point() + \n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(size = 14, face = \"bold\"),\n    axis.title.y = element_text(size = 14, face = \"bold\"),\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5)\n  ) +\n  ggtitle(\"Customized ggplot2 Plot\")\n</code></pre>"},{"location":"chapters/05_grammar_of_graphics/#putting-it-all-together","title":"Putting It All Together","text":"<p>Here is a complete example that combines all the elements discussed above:</p> <pre><code># Complete example\nggplot(data, aes(x = x, y = y)) + \n  geom_point(color = \"blue\", size = 3, alpha = 0.6) + \n  scale_x_continuous(name = \"X Axis\", limits = c(-3, 3), breaks = seq(-3, 3, 1)) +\n  scale_y_continuous(name = \"Y Axis\", limits = c(-3, 3), breaks = seq(-3, 3, 1)) +\n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(size = 14, face = \"bold\"),\n    axis.title.y = element_text(size = 14, face = \"bold\"),\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5)\n  ) +\n  ggtitle(\"Complete ggplot2 Example\")\n</code></pre> <p>By understanding and utilizing the grammar of graphics in <code>ggplot2</code>, you can create a wide variety of visualizations to effectively communicate your data insights.</p> <p>To learn more about visualizing data with <code>ggplot2</code>, refer to our Data Visualization with ggplot2 course.</p>"},{"location":"chapters/references/","title":"References","text":"<ol> <li> <p>Nancy J Hoebelheinrich, Katarzyna Biernacka, Michelle Brazas, Leyla Jael Castro, Nicola Fiore, Margareta Hellstrom, Emma Lazzeri, Ellen Leenarts, Paula Maria Martinez Lavanchy, Elizabeth Newbold, Amy Nurnberger, Esther Plomp, Lucia Vaira, Celia W G van Gelder, and Angus Whyte. Recommendations for a minimal metadata set to aid harmonised discovery of learning resources. June 2022. URL: https://doi.org/10.15497/RDA00073, doi:10.15497/RDA00073.\u00a0\u21a9</p> </li> <li> <p>Leyla Garcia, B\u00e9r\u00e9nice Batut, Melissa L. Burke, Mateusz Kuzak, Fotis Psomopoulos, Ricardo Arcila, Teresa K. Attwood, Niall Beard, Denise Carvalho-Silva, Alexandros C. Dimopoulos, Victoria Dominguez Del Angel, Michel Dumontier, Kim T. Gurwitz, Roland Krause, Peter McQuilton, Loredana Le Pera, Sarah L. Morgan, P\u00e4ivi Rauste, Allegra Via, Pascal Kahlem, Gabriella Rustici, Celia W.G. Van Gelder, and Patricia M. Palagi. Ten simple rules for making training materials FAIR. PLoS Computational Biology, 16(5):1\u20139, 2020. doi:10.1371/journal.pcbi.1007854.\u00a0\u21a9</p> </li> <li> <p>When we share, everyone wins. Accessed: 2022-08-11. URL: https://creativecommons.org/.\u00a0\u21a9</p> </li> <li> <p>Open source licenses: types and comparison. Accessed: 2023-02-10. URL: https://snyk.io/learn/open-source-licenses/.\u00a0\u21a9</p> </li> <li> <p>Jon Ison, Mat\u00fa\u0161 Kala\u0161, Inge Jonassen, Dan Bolser, Mahmut Uludag, Hamish McWilliam, James Malone, Rodrigo Lopez, Steve Pettifer, and Peter Rice. EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats. Bioinformatics, 29(10):1325\u20131332, 03 2013. URL: https://doi.org/10.1093/bioinformatics/btt113, arXiv:https://academic.oup.com/bioinformatics/article-pdf/29/10/1325/710075/btt113.pdf, doi:10.1093/bioinformatics/btt113.\u00a0\u21a9</p> </li> <li> <p>Scott Chacon and Ben Straub. Pro Git. Apress, 2014. URL: https://git-scm.com/book/en/v2.\u00a0\u21a9</p> </li> <li> <p>Visual Studio Code Documentation Team. Source control in visual studio code. Accessed: 2024-11-05. URL: https://code.visualstudio.com/docs/sourcecontrol/overview.\u00a0\u21a9</p> </li> <li> <p>GitHub Documentation Team. Caching Your GitHub Credentials in Git. Accessed: 2024-11-05. URL: https://docs.github.com/en/get-started/getting-started-with-git/caching-your-github-credentials-in-git.\u00a0\u21a9</p> </li> </ol>"}]}